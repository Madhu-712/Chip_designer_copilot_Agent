{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhu-712/Chip_designer_copilot_Agent/blob/main/LangGraph/Chip_design_LangGraph_Multi_Agent_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MultiAgent LangGraph Agent\n",
        "In this notebook multiple Agents pattern is illustrated .Here different  agents work with one another to  accomplish complex tasks execution."
      ],
      "metadata": {
        "id": "KySqk_p8Malv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIxfx9mrZWFF",
        "outputId": "bfdc609a-47bf-4840-8bac-ee494ba829a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.31-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.52)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.8 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.63-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.31)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.13.2)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.3.31-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.63-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: xxhash, python-dotenv, ormsgpack, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, dataclasses-json, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain_community, langchain-experimental\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-experimental-0.3.4 langchain_community-0.3.21 langgraph-0.3.31 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.63 marshmallow-3.26.1 mypy-extensions-1.0.0 ormsgpack-1.9.1 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install -U langgraph langchain-experimental langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq langchain groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeTD1mv7ZX0I",
        "outputId": "40620522-9f9b-42ce-e081-20fe67dfe644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting groq\n",
            "  Downloading groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.0.0)\n",
            "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading groq-0.22.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain_groq\n",
            "Successfully installed groq-0.22.0 langchain_groq-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing API keys"
      ],
      "metadata": {
        "id": "WoCmRsOuNUuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"GROQ_API_KEY:\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnRY0-MJZYcc",
        "outputId": "4a93f723-999d-489c-d3f1-a958b1135ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GROQ_API_KEY:\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gsk_9Hvs8nkYUZ7sf5Q1KQbnWGdyb3FYEsw2GFgvM638fKuIxBa4uKyhuyul"
      ],
      "metadata": {
        "id": "H_cMSAnrZY_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY:\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvFL7G5uZZer",
        "outputId": "223d5b47-d48b-43f4-f2d4-38c9fe5cfb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TAVILY_API_KEY:\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "# This executes code locally, which can be unsafe\n",
        "repl = PythonREPL()\n",
        "\n",
        "\n",
        "@tool\n",
        "def python_repl_tool(\n",
        "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
        "):\n",
        "    \"\"\"Use this to execute python code and do math. If you want to see the output of a value,\n",
        "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
        "    try:\n",
        "        result = repl.run(code)\n",
        "    except BaseException as e:\n",
        "        return f\"Failed to execute. Error: {repr(e)}\"\n",
        "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
        "    return result_str"
      ],
      "metadata": {
        "id": "DrN3B7Abm2DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Agents"
      ],
      "metadata": {
        "id": "IjiqXufqN0vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "#from langchain_anthropic import ChatAnthropic\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import MessagesState, END\n",
        "from langgraph.types import Command\n",
        "\n",
        "llm = ChatGroq(model=\"Llama3-8b-8192\",temperature=0.0)\n",
        "#llm = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n",
        "#llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.0)\n",
        "def get_next_node(last_message: BaseMessage, goto: str):\n",
        "    if \"FINAL ANSWER\" in last_message.content:\n",
        "        # Any agent decided the work is done\n",
        "        return END\n",
        "    return goto\n",
        "def orchestrator_agent(role, instructions):\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [(\"system\", f\"You are a {role}. {instructions}\"), (\"human\", \"{input}\")]\n",
        "    )\n",
        "    # Assuming llm is defined in the scope where this function is called\n",
        "    return prompt | llm\n",
        "def orchestrator_node(\n",
        "    state: MessagesState,\n",
        ") -> Command[Literal[\"Orchestrator\", END]]:\n",
        "    result = orchestrator_agent.invoke(state)\n",
        "    goto = get_next_node(result[\"messages\"][-1], \"Orchestrator\")\n",
        "    # wrap in a human message, as not all providers allow\n",
        "    # AI message at the last position of the input messages list\n",
        "    result[\"messages\"][-1] = HumanMessage(\n",
        "        content=result[\"messages\"][-1].content, name=\"Orchestrator\"\n",
        "    )\n",
        "    return Command(\n",
        "        update={\n",
        "            # share internal message history of orchestrator agent with other agents\n",
        "            \"messages\": result[\"messages\"],\n",
        "        },\n",
        "        goto=goto,\n",
        "    )"
      ],
      "metadata": {
        "id": "pk1E7p76m2oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AI_model_agent(role,instructions):\n",
        "    prompt=ChatPromptTemplate.from_messages(\n",
        "         [(\"system\", f\"You are a {role}. {instructions}\"), (\"human\", \"{input}\")]\n",
        "    )\n",
        "    return prompt | llm\n",
        "def AI_model_node(\n",
        "    state: MessagesState,\n",
        ") -> Command[Literal[\"AI model\", END]]:\n",
        "    result = AI_model_agent.invoke(state)\n",
        "    goto = get_next_node(result[\"messages\"][-1], \"AI model\")\n",
        "    # wrap in a human message, as not all providers allow\n",
        "    # AI message at the last position of the input messages list\n",
        "    result[\"messages\"][-1] = HumanMessage(\n",
        "        content=result[\"messages\"][-1].content, name=\"AI model\"\n",
        "    )\n",
        "    return Command(\n",
        "        update={\n",
        "            # share internal message history of AI model agent with other agents\n",
        "            \"messages\": result[\"messages\"],\n",
        "        },\n",
        "        goto=goto,\n",
        "    )"
      ],
      "metadata": {
        "id": "R31tGOIym3PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Design_agent(role,instructions):\n",
        "    prompt=ChatPromptTemplate.from_messages(\n",
        "         [(\"system\", f\"You are a {role}. {instructions}\"), (\"human\", \"{input}\")]\n",
        "    )\n",
        "    return prompt | llm\n",
        "def Design_node(\n",
        "    state: MessagesState,\n",
        ") -> Command[Literal[\"Design\", END]]:\n",
        "    result = Design_agent.invoke(state)\n",
        "    goto = get_next_node(result[\"messages\"][-1], \"Design\")\n",
        "    # wrap in a human message, as not all providers allow\n",
        "    # AI message at the last position of the input messages list\n",
        "    result[\"messages\"][-1] = HumanMessage(\n",
        "        content=result[\"messages\"][-1].content, name=\"Design\"\n",
        "    )\n",
        "    return Command(\n",
        "        update={\n",
        "            # share internal message history of Design agent with other agents\n",
        "            \"messages\": result[\"messages\"],\n",
        "        },\n",
        "        goto=goto,\n",
        "    )"
      ],
      "metadata": {
        "id": "_nDxG9fQm33W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_agent(role, instructions):\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [(\"system\", f\"You are a {role}. {instructions}\"), (\"human\", \"{input}\")]\n",
        "    )\n",
        "    # Assuming llm is defined in the scope where this function is called\n",
        "    return prompt | llm"
      ],
      "metadata": {
        "id": "M57vEGYYvnIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Orchestrator= create_agent(\"Orchestrator\", \"Orchestratea AI agent and design agent and prepares final chip design report\")\n",
        "AI_model = create_agent(\"AI model\", \"Analyze the chip architecture  and suggest power,area optimization and improvements\")\n",
        "Design = create_agent(\"Design\", \"Review & Implement the suggested improvements in the chip design and generate a formal chip design report\")"
      ],
      "metadata": {
        "id": "q6TluXGpm4eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langgraph.graph import StateGraph, START, END  # Import START"
      ],
      "metadata": {
        "id": "33Vxv-Wvvyd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create and compile the workflow"
      ],
      "metadata": {
        "id": "JTyKZTB0OD6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(state_schema=dict)  # Initialize without 'nodes'\n",
        "# Add nodes individually using add_node\n",
        "workflow.add_node(\"Orchestrator\", Orchestrator)\n",
        "workflow.add_node(\"AI model\", AI_model) #Corrected this line\n",
        "workflow.add_node(\"Design\", Design)\n",
        "\n",
        "\n",
        "# Define the flow of our multi-agent system, potentially starting from START\n",
        "workflow.add_edge(START, \"Orchestrator\")  # If 'coder' is the initial node\n",
        "workflow.add_edge(\"Orchestrator\", \"AI model\")\n",
        "workflow.add_edge(\"AI model\", \"Design\")\n",
        "workflow.add_edge(\"Design\", END)\n",
        "\n",
        "# Compile the workflow\n",
        "chain = workflow.compile()"
      ],
      "metadata": {
        "id": "FDHBj-h5ZaA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(chain.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "-7mM93u3wIB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"how to choose the no. Of input  pins in a Chip architecture and Generate a report emphasizing this?\"\n",
        "\n",
        "result = chain.invoke({\"input\": task})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfJO-poytXrV",
        "outputId": "ecd4e170-3965-4498-bd8c-b9e08dd3764d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='**Formal Chip Design Report**\\n\\n**Introduction:**\\n\\nThis report presents the design improvements and optimizations suggested for the provided chip architecture. The report is divided into three main sections: Power Optimization, Area Optimization, and Improvements. The suggested improvements aim to reduce power consumption, minimize area, and enhance overall chip performance.\\n\\n**Power Optimization:**\\n\\n1. **Clock Gating:** Implement clock gating to reduce power consumption by disabling clock signals to unused logic blocks. This technique can reduce power consumption by up to 30%.\\n2. **Power Domains:** Divide the chip into power domains, allowing for independent power management and reducing power consumption. This technique can reduce power consumption by up to 20%.\\n3. **Voltage Scaling:** Implement voltage scaling to reduce power consumption during idle periods or when the chip is not performing critical tasks. This technique can reduce power consumption by up to 15%.\\n4. **Leakage Reduction:** Implement techniques to reduce leakage current, such as transistor sizing and body biasing. This technique can reduce power consumption by up to 10%.\\n\\n**Area Optimization:**\\n\\n1. **Logic Minimization:** Optimize the logic design to minimize the number of gates and reduce area. This technique can reduce area by up to 20%.\\n2. **Register Allocation:** Optimize register allocation to reduce the number of registers and minimize area. This technique can reduce area by up to 15%.\\n3. **Memory Optimization:** Optimize memory usage by reducing the number of memory accesses and using more efficient memory structures. This technique can reduce area by up to 10%.\\n4. **Floorplanning:** Optimize floorplanning to reduce wirelength and minimize area. This technique can reduce area by up to 5%.\\n\\n**Improvements:**\\n\\n1. **Data Path Optimization:** Optimize the data path to reduce the number of stages and minimize area. This technique can reduce area by up to 10%.\\n2. **Control Path Optimization:** Optimize the control path to reduce the number of control signals and minimize area. This technique can reduce area by up to 5%.\\n3. **Clock Distribution Network:** Optimize the clock distribution network to reduce skew and minimize area. This technique can reduce area by up to 5%.\\n4. **Power Distribution Network:** Optimize the power distribution network to reduce voltage drops and minimize area. This technique can reduce area by up to 5%.\\n\\n**Additional Recommendations:**\\n\\n1. **Use a more efficient instruction set architecture (ISA):** Consider using a more efficient ISA to reduce the number of instructions and minimize area.\\n2. **Use a more efficient memory hierarchy:** Consider using a more efficient memory hierarchy, such as a cache hierarchy, to reduce memory accesses and minimize area.\\n3. **Use a more efficient clocking scheme:** Consider using a more efficient clocking scheme, such as a dual-edge-triggered clock, to reduce clock skew and minimize area.\\n4. **Use a more efficient power management scheme:** Consider using a more efficient power management scheme, such as dynamic voltage and frequency scaling, to reduce power consumption and minimize area.\\n\\n**Conclusion:**\\n\\nThe suggested improvements and optimizations aim to reduce power consumption, minimize area, and enhance overall chip performance. By implementing these suggestions, the chip architecture can be optimized for better performance, power efficiency, and area utilization.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 670, 'prompt_tokens': 721, 'total_tokens': 1391, 'completion_time': 0.558333333, 'prompt_time': 0.099409284, 'queue_time': 0.018439843999999997, 'total_time': 0.657742617}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-0fa38319-bd02-44db-9010-64dd4e03ba78-0' usage_metadata={'input_tokens': 721, 'output_tokens': 670, 'total_tokens': 1391}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "# Access the content of the AIMessage object, which is a string\n",
        "markdown_content = result.content\n",
        "\n",
        "# Now pass the string content to Markdown\n",
        "print(Markdown(markdown_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orlvk3xxtYO-",
        "outputId": "d6cb1eb5-0394-421d-daec-5cbd83b504dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<IPython.core.display.Markdown object>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "display(Markdown(str(result)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1_-GNaP-tpdR",
        "outputId": "f479c5cb-db78-4d4f-cb4c-975b7b21a721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "content='**Formal Chip Design Report**\\n\\n**Introduction:**\\n\\nThis report presents the design improvements and optimizations suggested for the provided chip architecture. The report is divided into three main sections: Power Optimization, Area Optimization, and Improvements. The suggested improvements aim to reduce power consumption, minimize area, and enhance overall chip performance.\\n\\n**Power Optimization:**\\n\\n1. **Clock Gating:** Implement clock gating to reduce power consumption by disabling clock signals to unused logic blocks. This technique can reduce power consumption by up to 30%.\\n2. **Power Domains:** Divide the chip into power domains, allowing for independent power management and reducing power consumption. This technique can reduce power consumption by up to 20%.\\n3. **Voltage Scaling:** Implement voltage scaling to reduce power consumption during idle periods or when the chip is not performing critical tasks. This technique can reduce power consumption by up to 15%.\\n4. **Leakage Reduction:** Implement techniques to reduce leakage current, such as transistor sizing and body biasing. This technique can reduce power consumption by up to 10%.\\n\\n**Area Optimization:**\\n\\n1. **Logic Minimization:** Optimize the logic design to minimize the number of gates and reduce area. This technique can reduce area by up to 20%.\\n2. **Register Allocation:** Optimize register allocation to reduce the number of registers and minimize area. This technique can reduce area by up to 15%.\\n3. **Memory Optimization:** Optimize memory usage by reducing the number of memory accesses and using more efficient memory structures. This technique can reduce area by up to 10%.\\n4. **Floorplanning:** Optimize floorplanning to reduce wirelength and minimize area. This technique can reduce area by up to 5%.\\n\\n**Improvements:**\\n\\n1. **Data Path Optimization:** Optimize the data path to reduce the number of stages and minimize area. This technique can reduce area by up to 10%.\\n2. **Control Path Optimization:** Optimize the control path to reduce the number of control signals and minimize area. This technique can reduce area by up to 5%.\\n3. **Clock Distribution Network:** Optimize the clock distribution network to reduce skew and minimize area. This technique can reduce area by up to 5%.\\n4. **Power Distribution Network:** Optimize the power distribution network to reduce voltage drops and minimize area. This technique can reduce area by up to 5%.\\n\\n**Additional Recommendations:**\\n\\n1. **Use a more efficient instruction set architecture (ISA):** Consider using a more efficient ISA to reduce the number of instructions and minimize area.\\n2. **Use a more efficient memory hierarchy:** Consider using a more efficient memory hierarchy, such as a cache hierarchy, to reduce memory accesses and minimize area.\\n3. **Use a more efficient clocking scheme:** Consider using a more efficient clocking scheme, such as a dual-edge-triggered clock, to reduce clock skew and minimize area.\\n4. **Use a more efficient power management scheme:** Consider using a more efficient power management scheme, such as dynamic voltage and frequency scaling, to reduce power consumption and minimize area.\\n\\n**Conclusion:**\\n\\nThe suggested improvements and optimizations aim to reduce power consumption, minimize area, and enhance overall chip performance. By implementing these suggestions, the chip architecture can be optimized for better performance, power efficiency, and area utilization.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 670, 'prompt_tokens': 721, 'total_tokens': 1391, 'completion_time': 0.558333333, 'prompt_time': 0.099409284, 'queue_time': 0.018439843999999997, 'total_time': 0.657742617}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-0fa38319-bd02-44db-9010-64dd4e03ba78-0' usage_metadata={'input_tokens': 721, 'output_tokens': 670, 'total_tokens': 1391}"
          },
          "metadata": {}
        }
      ]
    }
  ]
}